{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22b1cc7",
   "metadata": {},
   "source": [
    "# Document Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:10:34.857862Z",
     "start_time": "2024-11-29T19:10:34.534996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text = \"\"\"The world of street food is a vibrant tapestry of flavors and cultures. From sizzling skewers to spicy tacos, every corner of the globe has its own unique offerings. Vendors often  up shop in bustling markets or on busy street corners, attracting hungry passersby with mouthwatering aromas.\n",
    "\n",
    "One of the best things about street food is its accessibility. It’s quick, affordable, and often made fresh right in front of you. Whether it’s a steaming bowl of pho in Vietnam or a crispy samosa in India, there’s something for everyone to enjoy.\n",
    "\n",
    "Street food also brings people together. Friends and families gather around food stalls, sharing dishes and stories. It’s a social experience that transcends language and culture, creating connections over a shared love of good eats.\n",
    "\n",
    "Finally, street food is constantly evolving. Chefs are experimenting with traditional recipes, adding modern twists and fusion flavors. This creativity keeps the scene exciting and ensures there’s always something new to try.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6262ff",
   "metadata": {},
   "source": [
    "\n",
    "## Length Based Splitter\n",
    "\n",
    "- Token-based: Splits text based on the number of tokens, which is useful when working with language models.\n",
    "- Character-based: Splits text based on the number of characters, which can be more consistent across different types of text.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c4d29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:10:36.883551Z",
     "start_time": "2024-11-29T19:10:36.880422Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=100, chunk_overlap=20\n",
    ")\n",
    "\n",
    "\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "print(type(docs))\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "print(docs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51b117dd8269f2",
   "metadata": {},
   "source": [
    "## Text-strucutre based splitter\n",
    "\n",
    "- The RecursiveCharacterTextSplitter attempts to keep larger units (e.g., paragraphs) intact.\n",
    "- If a unit exceeds the chunk size, it moves to the next level (e.g., sentences).\n",
    "- This process continues down to the word level if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56200d94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:10:39.281501Z",
     "start_time": "2024-11-29T19:10:39.277815Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=10)\n",
    "\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "print(type(docs))\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a061316f",
   "metadata": {},
   "source": [
    "## Document-structured based\n",
    "- Preserves the logical organization of the document\n",
    "- Maintains context within each chunk\n",
    "- Can be more effective for downstream tasks like retrieval or summarization\n",
    "\n",
    "**Examples of structure-based splitting:**\n",
    "- Markdown: Split based on headers (e.g., #, ##, ###)\n",
    "- HTML: Split using tags\n",
    "- JSON: Split by object or array elements\n",
    "- Code: Split by functions, classes, or logical blocks\n",
    "\n",
    "### Markdown Splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "# read markdown file\n",
    "with open(\"data/sample.md\", \"r\") as f:\n",
    "    md_text = f.read()\n",
    "    \n",
    "md_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "\n",
    "docs = markdown_splitter.split_text(md_text)\n",
    "\n",
    "print(type(docs))\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Char-level splits\n",
    "from attr import s\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = 10\n",
    "chunk_overlap = 2\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "# Split\n",
    "splits = text_splitter.split_documents(docs)\n",
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0eb5d9",
   "metadata": {},
   "source": [
    "### HTML Splitter\n",
    "#### Header Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1>Foo</h1>\n",
    "            <p>Some intro text about Foo.</p>\n",
    "            <div>\n",
    "                <h2>Bar main section</h2>\n",
    "                <p>Some intro text about Bar.</p>\n",
    "                <h3>Bar subsection 1</h3>\n",
    "                <p>Some text about the first subtopic of Bar.</p>\n",
    "                <h3>Bar subsection 2</h3>\n",
    "                <p>Some text about the second subtopic of Bar.</p>\n",
    "            </div>\n",
    "            <div>\n",
    "                <h2>Baz</h2>\n",
    "                <p>Some text about Baz</p>\n",
    "            </div>\n",
    "            <br>\n",
    "            <p>Some concluding text about Foo</p>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3e1b1",
   "metadata": {},
   "source": [
    "#### Section Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLSectionSplitter\n",
    "\n",
    "\n",
    "\n",
    "headers_to_split_on = [(\"h1\", \"Header 1\"), (\"h2\", \"Header 2\")]\n",
    "\n",
    "html_splitter = HTMLSectionSplitter(headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad26a53",
   "metadata": {},
   "source": [
    "## Semantic Meaning Based\n",
    "\n",
    "- Start with the first few sentences and generate an embedding.\n",
    "- Move to the next group of sentences and generate another embedding (e.g., using a sliding window approach).\n",
    "- Compare the embeddings to find significant differences, which indicate potential \"break points\" between semantic sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70fa617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "# embeddings: Embeddings,\n",
    "# buffer_size: int = 1,\n",
    "# add_start_index: bool = False,\n",
    "# breakpoint_threshold_type: BreakpointThresholdType = \"percentile\",\n",
    "# breakpoint_threshold_amount: Optional[float] = None,\n",
    "# number_of_chunks: Optional[int] = None,\n",
    "# sentence_split_regex: str = r\"(?<=[.?!])\\s+\",\n",
    "# min_chunk_size: Optional[int] = None,\n",
    "text_splitter = SemanticChunker(embedding_model,number_of_chunks=3)\n",
    "\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "print(type(docs))\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "\n",
    "docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4611939",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
