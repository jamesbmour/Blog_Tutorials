{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e8de950",
   "metadata": {},
   "source": [
    "# LangChain Part 3: Output Parsing\n",
    "- Important when using agents with tools e.g. calculator , search engine \n",
    "- Many systems expect data in specific way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6509fe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a language model, so I don't have emotions or feelings like humans do, but I'm functioning properly and ready to help you with any questions or tasks you have. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"meta-llama/llama-3.2-3b-instruct:free\",\n",
    "    temperature=0.2,\n",
    ")\n",
    "# llm = ChatOllama(model='llama3.2', temperature=0.2, max_tokens=512)\n",
    "\n",
    "result = llm.invoke(\"Hello, how are you today?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b032192b",
   "metadata": {},
   "source": [
    "# CSV Parser \n",
    "- Used when want to return a list of comma-separated Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38186839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Instructions:\n",
      " Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz` \n",
      "\n",
      "{'_type': 'prompt',\n",
      " 'input_variables': ['subject'],\n",
      " 'metadata': None,\n",
      " 'name': None,\n",
      " 'optional_variables': [],\n",
      " 'output_parser': None,\n",
      " 'partial_variables': {'format_instructions': 'Your response should be a list '\n",
      "                                              'of comma separated values, eg: '\n",
      "                                              '`foo, bar, baz` or '\n",
      "                                              '`foo,bar,baz`'},\n",
      " 'tags': None,\n",
      " 'template': 'List five {subject}. \\n{format_instructions}',\n",
      " 'template_format': 'f-string',\n",
      " 'validate_template': False}\n",
      "\n",
      "Result:\n",
      " ['Labrador', 'German Shepherd', 'Poodle', 'Beagle', 'Rottweiler']\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from pprint import pp\n",
    "from tempfile import template\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(\"Format Instructions:\\n\",format_instructions, \"\\n\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}. \\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "pprint(prompt.dict())\n",
    "\n",
    "# Create a model that uses the prompt\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# Invoke the model\n",
    "result = chain.invoke({\"subject\": \"dog breeds\"})\n",
    "\n",
    "print('\\nResult:\\n',result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2563639f",
   "metadata": {},
   "source": [
    "# Datetime Parser\n",
    "- Used when want to return a date in a specific format\n",
    "- Useful for applications that require a specific date format like a calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ee53d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datetime Result:\n",
      " 2024-11-20 14:41:04.123456\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Create a new prompt template for datetime parsing\n",
    "datetime_prompt = PromptTemplate(\n",
    "    template=\"What is the current date and time in UTC?\\n{format_instructions}\",\n",
    "    input_variables=[\"format_instructions\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Create a chain with the new prompt and the existing llm and output_parser\n",
    "datetime_chain = datetime_prompt | llm | output_parser\n",
    "\n",
    "# Invoke the chain\n",
    "datetime_result = datetime_chain.invoke({})\n",
    "\n",
    "print('\\nDatetime Result:\\n', datetime_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195acf92",
   "metadata": {},
   "source": [
    "# Enum Parser\n",
    "- Used when want to return a list of items in a specific format\n",
    "- e.g. list of colors, list of countries\n",
    "- Useful for applications that require a specific list of items like a dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "499184a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'enum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     SATURDAY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaturday\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create a new output parser for the enum\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m enum_output_parser \u001b[38;5;241m=\u001b[39m \u001b[43mEnumOutputParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43menum_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDayOfWeek\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create a new prompt template for the enum\u001b[39;00m\n\u001b[1;32m     19\u001b[0m enum_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m     20\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat day of the week is it today?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{format_instructions}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_instructions\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     22\u001b[0m     partial_variables\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_instructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: enum_output_parser\u001b[38;5;241m.\u001b[39mget_format_instructions()},\n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/blog-tutorials-M8bgSKgB-py3.12/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/blog-tutorials-M8bgSKgB-py3.12/lib/python3.12/site-packages/pydantic/_internal/_decorators_v1.py:148\u001b[0m, in \u001b[0;36mmake_v1_generic_root_validator.<locals>._wrapper1\u001b[0;34m(values, _)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapper1\u001b[39m(values: RootValidatorValues, _: core_schema\u001b[38;5;241m.\u001b[39mValidationInfo) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RootValidatorValues:\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/blog-tutorials-M8bgSKgB-py3.12/lib/python3.12/site-packages/langchain_core/utils/pydantic.py:208\u001b[0m, in \u001b[0;36mpre_init.<locals>.wrapper\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    205\u001b[0m             values[name] \u001b[38;5;241m=\u001b[39m field_info\u001b[38;5;241m.\u001b[39mdefault\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Call the decorated function\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/blog-tutorials-M8bgSKgB-py3.12/lib/python3.12/site-packages/langchain/output_parsers/enum.py:17\u001b[0m, in \u001b[0;36mEnumOutputParser.raise_deprecation\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@pre_init\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_deprecation\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m---> 17\u001b[0m     enum \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mvalue, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m enum):\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnum values must be strings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'enum'"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from enum import Enum\n",
    "\n",
    "# Define an enum for the days of the week\n",
    "class DayOfWeek(Enum):\n",
    "    SUNDAY = \"Sunday\"\n",
    "    MONDAY = \"Monday\"\n",
    "    TUESDAY = \"Tuesday\"\n",
    "    WEDNESDAY = \"Wednesday\"\n",
    "    THURSDAY = \"Thursday\"\n",
    "    FRIDAY = \"Friday\"\n",
    "    SATURDAY = \"Saturday\"\n",
    "    \n",
    "# Create a new output parser for the enum\n",
    "enum_output_parser = EnumOutputParser(enum_class=DayOfWeek)\n",
    "\n",
    "# Create a new prompt template for the enum\n",
    "enum_prompt = PromptTemplate(\n",
    "    template=\"What day of the week is it today?\\n{format_instructions}\",\n",
    "    input_variables=[\"format_instructions\"],\n",
    "    partial_variables={\"format_instructions\": enum_output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Create a chain with the new prompt and the existing llm and output_parser\n",
    "enum_chain = enum_prompt | llm | enum_output_parser\n",
    "\n",
    "# Invoke the chain\n",
    "enum_result = enum_chain.invoke({})\n",
    "\n",
    "print('\\nEnum Result:\\n', enum_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb8042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datetime Result:\n",
      " 2024-11-20 14:41:47.123456\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c49270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog-tutorials-M8bgSKgB-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
