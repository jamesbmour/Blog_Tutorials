{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T11:36:27.743109Z",
     "start_time": "2024-11-07T11:36:27.737611Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_openai import OpenAI\n",
    "import getpass\n",
    "import os\n",
    "from pydantic.v1 import BaseModel\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ollama Chat",
   "id": "a370140ae13e6a2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:36:27.803286Z",
     "start_time": "2024-11-07T11:36:27.769239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = OllamaLLM(model=\"qwen2.5:0.5b\")\n"
   ],
   "id": "1eeba3dad35156a5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:36:27.810873Z",
     "start_time": "2024-11-07T11:36:27.809335Z"
    }
   },
   "cell_type": "code",
   "source": "chain = prompt | llm\n",
   "id": "b52d122b6ce34911",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:36:29.758017Z",
     "start_time": "2024-11-07T11:36:27.831672Z"
    }
   },
   "cell_type": "code",
   "source": "print(chain.invoke(\"What is Langchain?\"))",
   "id": "4d25ca2fbf5d5a55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain is an AI language processing service that provides developers and researchers with a tool to generate text from structured data. In short, it's like a natural language generation (NLG) platform, but instead of generating text based on textual descriptions, it can automatically generate high-quality written content based on the provided structured data.\n",
      "\n",
      "To better understand Langchain:\n",
      "1. It supports multiple languages: The system is available in English, Chinese, and other major languages.\n",
      "2. It has a large library of pre-trained models to support various types of tasks (e.g., text generation for news, writing reviews).\n",
      "3. It can be used as an AI language model that provides insights or outputs information through natural language interaction.\n",
      "4. It's useful in fields like customer service, document analysis, and content creation where structured data is common.\n",
      "\n",
      "I hope this explanation helps clarify the concept of Langchain for you! Let me know if you have any more questions about it.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ollama Streaming",
   "id": "f2709dd5c192312f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:36:29.930710Z",
     "start_time": "2024-11-07T11:36:29.835817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in llm.stream(\"What is the capital of France?\"):\n",
    "    print(chunk, end=\"|\", flush=True)\n"
   ],
   "id": "e62943abb4e47a16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The| capital| of| France| is| Paris|.||"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# OpenAI Chat",
   "id": "d033ca7a7765a7c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:36:29.993461Z",
     "start_time": "2024-11-07T11:36:29.961938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.4,\n",
    "    max_tokens=52,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ],
   "id": "485b5a69f946f725",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:38:04.335156Z",
     "start_time": "2024-11-07T11:38:03.793138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "messages = [HumanMessage(content=\"What is the name of the most populous state in the USA?\")]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n"
   ],
   "id": "f29fd25b8b03e95c",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:38:05.831357Z",
     "start_time": "2024-11-07T11:38:05.828180Z"
    }
   },
   "cell_type": "code",
   "source": "ai_msg.content\n",
   "id": "61723fe3b73e1b4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The most populous state in the USA is California.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T11:36:30.539134Z",
     "start_time": "2024-11-07T11:36:30.536702Z"
    }
   },
   "cell_type": "code",
   "source": "ai_msg.response_metadata",
   "id": "374980303c121857",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 5, 'prompt_tokens': 31, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9ee9e968ea', 'finish_reason': 'stop', 'logprobs': None}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
