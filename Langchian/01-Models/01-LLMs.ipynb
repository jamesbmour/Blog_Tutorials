{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:13:44.143043Z",
     "start_time": "2024-11-09T10:13:44.019231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n"
   ],
   "id": "d84f7735edbc5c15",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chat with Ollama",
   "id": "a5ab62d0aaa46c81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:13:44.149054Z",
     "start_time": "2024-11-09T10:13:44.147109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ],
   "id": "b60ed0185134e4ae",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:13:44.184001Z",
     "start_time": "2024-11-09T10:13:44.154982Z"
    }
   },
   "cell_type": "code",
   "source": "llm = ChatOllama(model='qwen2.5:0.5b', temperature=0.5)\n",
   "id": "df3e3216054a83c5",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:13:45.596622Z",
     "start_time": "2024-11-09T10:13:44.193875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "r = llm.invoke(\"Hello, how are you today?\")\n",
    "print(r)"
   ],
   "id": "d40e65c7aa3779",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I'm just an AI language model, so I don't have feelings like humans do. However, I'm here to help answer questions and provide information to the best of my abilities. How can I assist you today?\" additional_kwargs={} response_metadata={'model': 'qwen2.5:0.5b', 'created_at': '2024-11-09T10:13:45.593618Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 1397289208, 'load_duration': 568376542, 'prompt_eval_count': 36, 'prompt_eval_duration': 331000000, 'eval_count': 47, 'eval_duration': 269000000} id='run-b272efc0-cdfe-4bfc-8d27-30b6b5fde9d9-0' usage_metadata={'input_tokens': 36, 'output_tokens': 47, 'total_tokens': 83}\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:13:45.614937Z",
     "start_time": "2024-11-09T10:13:45.612062Z"
    }
   },
   "cell_type": "code",
   "source": "r.content",
   "id": "3af7ce997bcdb296",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just an AI language model, so I don't have feelings like humans do. However, I'm here to help answer questions and provide information to the best of my abilities. How can I assist you today?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chat with OpenAI",
   "id": "f16318457690a31a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:13:45.654539Z",
     "start_time": "2024-11-09T10:13:45.619771Z"
    }
   },
   "cell_type": "code",
   "source": "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.5, max_tokens=52)",
   "id": "d592320046c916f7",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:13:46.721500Z",
     "start_time": "2024-11-09T10:13:45.661070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "r = llm.invoke(\"Hello, how are you today?\")\n",
    "print(r)"
   ],
   "id": "6b5fefa9644bbdc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with anything you need. How can I assist you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 14, 'total_tokens': 51, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-5b93d86e-9ebf-4b91-b3e0-5f125d6a8291-0' usage_metadata={'input_tokens': 14, 'output_tokens': 37, 'total_tokens': 51, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:13:46.798535Z",
     "start_time": "2024-11-09T10:13:46.796106Z"
    }
   },
   "cell_type": "code",
   "source": "r.content",
   "id": "89a66a84fc7cff23",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with anything you need. How can I assist you today?\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# OpenRouter Chat",
   "id": "26b56e18411e09bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:47:57.416402Z",
     "start_time": "2024-11-09T10:47:50.639936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"meta-llama/llama-3.2-3b-instruct:free\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=100,\n",
    "\n",
    ")\n",
    "\n",
    "result = llm.invoke(\"Hello, how are you today?\")\n",
    "result.content"
   ],
   "id": "eccacd36a4184379",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm just a language model, so I don't have emotions or feelings like humans do, but I'm functioning properly and ready to help you with any questions or tasks you have. How can I assist you today?\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:47:08.839119Z",
     "start_time": "2024-11-09T10:47:08.837074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(result)\n",
    "\n",
    "print('\\n', result.content)"
   ],
   "id": "eb450b3e827b6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I'm just a language model, so I don't have emotions or feelings like humans do, but I'm functioning properly and ready to help you with any questions or tasks you have. How can I assist you today?\" additional_kwargs={'refusal': ''} response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 42, 'total_tokens': 86, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'meta-llama/llama-3.2-3b-instruct', 'system_fingerprint': 'fastcoe', 'finish_reason': 'stop', 'logprobs': None} id='run-53469d34-ff2e-463d-b3ba-170879642351-0' usage_metadata={'input_tokens': 42, 'output_tokens': 44, 'total_tokens': 86, 'input_token_details': {}, 'output_token_details': {}}\n",
      "\n",
      " I'm just a language model, so I don't have emotions or feelings like humans do, but I'm functioning properly and ready to help you with any questions or tasks you have. How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:13:48.551150Z",
     "start_time": "2024-11-09T10:13:48.545393Z"
    }
   },
   "cell_type": "code",
   "source": "result.schema()\n",
   "id": "bcebc3e569b187ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'InputTokenDetails': {'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'cache_creation': {'title': 'Cache Creation', 'type': 'integer'},\n",
       "    'cache_read': {'title': 'Cache Read', 'type': 'integer'}},\n",
       "   'title': 'InputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'InvalidToolCall': {'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Error'},\n",
       "    'type': {'const': 'invalid_tool_call',\n",
       "     'enum': ['invalid_tool_call'],\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error'],\n",
       "   'title': 'InvalidToolCall',\n",
       "   'type': 'object'},\n",
       "  'OutputTokenDetails': {'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'reasoning': {'title': 'Reasoning', 'type': 'integer'}},\n",
       "   'title': 'OutputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'ToolCall': {'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'type': {'const': 'tool_call',\n",
       "     'enum': ['tool_call'],\n",
       "     'title': 'Type',\n",
       "     'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id'],\n",
       "   'title': 'ToolCall',\n",
       "   'type': 'object'},\n",
       "  'UsageMetadata': {'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'},\n",
       "    'input_token_details': {'$ref': '#/$defs/InputTokenDetails'},\n",
       "    'output_token_details': {'$ref': '#/$defs/OutputTokenDetails'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens'],\n",
       "   'title': 'UsageMetadata',\n",
       "   'type': 'object'}},\n",
       " 'additionalProperties': True,\n",
       " 'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       " 'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "    {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "     'type': 'array'}],\n",
       "   'title': 'Content'},\n",
       "  'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "  'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "  'type': {'const': 'ai',\n",
       "   'default': 'ai',\n",
       "   'enum': ['ai'],\n",
       "   'title': 'Type',\n",
       "   'type': 'string'},\n",
       "  'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Name'},\n",
       "  'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Id'},\n",
       "  'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "  'tool_calls': {'default': [],\n",
       "   'items': {'$ref': '#/$defs/ToolCall'},\n",
       "   'title': 'Tool Calls',\n",
       "   'type': 'array'},\n",
       "  'invalid_tool_calls': {'default': [],\n",
       "   'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "   'title': 'Invalid Tool Calls',\n",
       "   'type': 'array'},\n",
       "  'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None}},\n",
       " 'required': ['content'],\n",
       " 'title': 'AIMessage',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T10:13:48.646511Z",
     "start_time": "2024-11-09T10:13:48.644777Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "de5b34d34a30d641",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
